{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cecbfa9-0038-4afa-84c8-e9717bcff216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50dfb5-0bc4-4215-856c-02d67e72edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87449ca3-3ae6-4ec0-a310-4d4539f7c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde6db26-e0ec-4f0d-8383-1a88635261ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"nlp2.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36929031-2701-437a-bce9-4b7cdb3ab844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ac3a2-a945-45c0-a3b3-7c38b41930d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import on_islem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc40e9-d5eb-4508-96ee-be97997400ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text_2\"] = df[\"Text\"].apply(on_islem.pre_processing)\n",
    "df[\"Text_2\"] = df[\"Text_2\"].apply(on_islem.remove_space)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81914d7a-b027-465e-884e-7ecc85e1dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boÅŸ liste kontrolÃ¼\n",
    "df[df[\"Text_2\"].str[0].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be366c1-7b02-4960-ab55-2471981991ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index=df[df[\"Text_2\"].str[0].isnull()].index\n",
    "df=df.drop(df_index)\n",
    "df=df.reset_index()\n",
    "del df[\"index\"]\n",
    "df[df[\"Text_2\"].str[0].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec277ae-f56e-4f6f-bce8-4d19b0d4cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7c43c-05f9-40d8-b6d4-1083453dd931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b61f8a-f325-409a-b424-0ce42a17b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text_3\"]=[' '.join(w for w in item) for item in df[\"Text_2\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f44d2-061f-4adf-8103-fa39be2483fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"Text_3\"].tolist())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2a3a2-5840-4369-8af7-5a38c45e4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b50b14-99a8-45da-8702-d17b855e5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638a670-a65c-4eef-ab81-d39fb6507056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text_4\"]= X.toarray().tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c65c3-d35f-4638-a934-f9780a885964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d482c05-5984-4192-93ec-8ff68368f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b7971-6ea4-4085-9cd9-30fa3ee348ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e1561-62d1-4da8-9cdb-86b8396379ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= TfidfVectorizer()\n",
    "X= vectorizer.fit_transform(df[\"Text_3\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e616bcb-7585-40de-8e88-493e74f800cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4d276-1cb3-4994-b98a-d53747640ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(X.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083937b-0c9d-447c-a568-23fd368a67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text_5\"]=X.toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf729007-aa54-49f0-97c7-cd853f7659bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66195f28-309e-4d51-beb7-19714407c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe6c88-8b6b-4885-8852-3c26132e98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12b384d4-a1b6-4e49-b644-732bd5ce582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3d039ae-f59a-4f57-9cc0-6e8b69c37953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_2</th>\n",
       "      <th>Text_3</th>\n",
       "      <th>Text_4</th>\n",
       "      <th>Text_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yapay Zeka Nedir, Ne Ä°ÅŸe Yarar?\\n\\nYapay zeka ...</td>\n",
       "      <td>[yapay, zeka, nedir, ne, iÅŸe, yarar, yapay, ze...</td>\n",
       "      <td>yapay zeka nedir ne iÅŸe yarar yapay zeka yz bi...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ðŸ”Ž Verilerinizi analiz edin: \\nChatGPT'yi kulla...</td>\n",
       "      <td>[veri, analiz, edin, chatgptyi, kullanarak, do...</td>\n",
       "      <td>veri analiz edin chatgptyi kullanarak doÄŸal di...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ã–ncelikle yapay zekanÄ±n ne olduÄŸunu, #dijitala...</td>\n",
       "      <td>[Ã¶ncelik, yapay, zeka, ne, olduÄŸunu, iÃ§, ne, Ã¶...</td>\n",
       "      <td>Ã¶ncelik yapay zeka ne olduÄŸunu iÃ§ ne Ã¶nemli ol...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9. Baidu Research: Ã‡in'in Ã¶nde gelen arama mot...</td>\n",
       "      <td>[baidu, research, Ã§in, Ã¶n, gele, ara, motor, b...</td>\n",
       "      <td>baidu research Ã§in Ã¶n gele ara motor baidun ar...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4. Microsoft AI: Microsoft'un yapay zeka tekno...</td>\n",
       "      <td>[microsoft, ai, microsoft, yapay, zeka, teknol...</td>\n",
       "      <td>microsoft ai microsoft yapay zeka teknoloji od...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Yapay Zeka Nedir, Ne Ä°ÅŸe Yarar?\\n\\nYapay zeka ...   \n",
       "1  ðŸ”Ž Verilerinizi analiz edin: \\nChatGPT'yi kulla...   \n",
       "2  Ã–ncelikle yapay zekanÄ±n ne olduÄŸunu, #dijitala...   \n",
       "3  9. Baidu Research: Ã‡in'in Ã¶nde gelen arama mot...   \n",
       "4  4. Microsoft AI: Microsoft'un yapay zeka tekno...   \n",
       "\n",
       "                                              Text_2  \\\n",
       "0  [yapay, zeka, nedir, ne, iÅŸe, yarar, yapay, ze...   \n",
       "1  [veri, analiz, edin, chatgptyi, kullanarak, do...   \n",
       "2  [Ã¶ncelik, yapay, zeka, ne, olduÄŸunu, iÃ§, ne, Ã¶...   \n",
       "3  [baidu, research, Ã§in, Ã¶n, gele, ara, motor, b...   \n",
       "4  [microsoft, ai, microsoft, yapay, zeka, teknol...   \n",
       "\n",
       "                                              Text_3  \\\n",
       "0  yapay zeka nedir ne iÅŸe yarar yapay zeka yz bi...   \n",
       "1  veri analiz edin chatgptyi kullanarak doÄŸal di...   \n",
       "2  Ã¶ncelik yapay zeka ne olduÄŸunu iÃ§ ne Ã¶nemli ol...   \n",
       "3  baidu research Ã§in Ã¶n gele ara motor baidun ar...   \n",
       "4  microsoft ai microsoft yapay zeka teknoloji od...   \n",
       "\n",
       "                                              Text_4  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              Text_5  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff644840-22e5-40b8-bedf-bff9fa592488",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/word2vec.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\utils.py:764\u001b[0m, in \u001b[0;36mSaveLoad.save\u001b[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 764\u001b[0m     \u001b[43m_pickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    765\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m object\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: file must have a 'write' attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Word2Vec(sentences\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText_2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), vector_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/word2vec.model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\models\\word2vec.py:1923\u001b[0m, in \u001b[0;36mWord2Vec.save\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save the model.\u001b[39;00m\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;124;03m    This saved model can be loaded again using :func:`~gensim.models.word2vec.Word2Vec.load`, which supports\u001b[39;00m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;124;03m    online training and getting vectors for vocabulary words.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1921\u001b[0m \n\u001b[0;32m   1922\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1923\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Word2Vec, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\utils.py:767\u001b[0m, in \u001b[0;36mSaveLoad.save\u001b[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    765\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m object\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `fname_or_handle` does not have write attribute\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparately\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\utils.py:611\u001b[0m, in \u001b[0;36mSaveLoad._smart_save\u001b[1;34m(self, fname, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    607\u001b[0m restores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_specials(\n\u001b[0;32m    608\u001b[0m     fname, separately, sep_limit, ignore, pickle_protocol, compress, subname,\n\u001b[0;32m    609\u001b[0m )\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 611\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;66;03m# restore attribs handled specially\u001b[39;00m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj, asides \u001b[38;5;129;01min\u001b[39;00m restores:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\utils.py:1442\u001b[0m, in \u001b[0;36mpickle\u001b[1;34m(obj, fname, protocol)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpickle\u001b[39m(obj, fname, protocol\u001b[38;5;241m=\u001b[39mPICKLE_PROTOCOL):\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pickle object `obj` to file `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \n\u001b[0;32m   1432\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1440\u001b[0m \n\u001b[0;32m   1441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fout:  \u001b[38;5;66;03m# 'b' for binary, needed on Windows\u001b[39;00m\n\u001b[0;32m   1443\u001b[0m         _pickle\u001b[38;5;241m.\u001b[39mdump(obj, fout, protocol\u001b[38;5;241m=\u001b[39mprotocol)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:177\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transport_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     transport_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 177\u001b[0m fobj \u001b[38;5;241m=\u001b[39m \u001b[43m_shortcut_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:363\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    361\u001b[0m     open_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m errors\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[38;5;241m=\u001b[39mbuffering, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/word2vec.model'"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences=df[\"Text_2\"].tolist(), vector_size=100, window=5, min_count=1)\n",
    "model.save(\"data/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd05f37-fd7a-4316-bf9a-4cedfa2f9bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdda572-cd5b-4524-983a-826c0d2634de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
